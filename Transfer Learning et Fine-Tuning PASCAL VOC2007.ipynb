{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP4.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSWxBQxqBTJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjNPqZN4IwGM",
        "colab_type": "text"
      },
      "source": [
        "## **Transfer Learning et Fine-Tuning PASCAL VOC2007**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvKPbfhoIu5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Exercice 2 : Perceptron avec Keras\n",
        "!pip install  --upgrade grpcio\n",
        "!pip uninstall tensorflow==1.15.0\n",
        "!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn_wvUVJI3Zs",
        "colab_type": "text"
      },
      "source": [
        "## **Exercice 1 : Modèle ResNet-50 avec Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0haFrjgFBkI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Activation, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.utils import np_utils \n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "model = ResNet50(include_top=True, weights='imagenet')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzzCyDTBB0G6",
        "colab_type": "text"
      },
      "source": [
        "# *Exercice* 2 : Extraction de « Deep Features »"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koQdI8kX9-XM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrl2bVAmB3eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# model.layers.pop()\n",
        "model = Model(inputs=model.inputs , outputs=model.layers[-2].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpn84ZbBCIX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr =0.01, momentum=0.9), metrics=['binary_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiZZqRHGGbQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "!wget  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "\n",
        "\n",
        "!mkdir -p ./content/data\n",
        "!tar xvf VOCtrainval_06-Nov-2007.tar -C ./content/data/   # -C ./datasets/trainset\n",
        "!tar xvf VOCtest_06-Nov-2007.tar -C ./content/data/  #-C ./datasets/testset\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "460obwIBLzBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "random.seed(2506)\n",
        "\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "LABELS = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "           'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "           'cow', 'diningtable', 'dog', 'horse',\n",
        "           'motorbike', 'person', 'pottedplant',\n",
        "           'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "\n",
        "class PascalVOCDataGenerator(object):\n",
        "    \"\"\"\n",
        "    PascalVOCDataGenerator defines a generator on the PascalVOC 2007 dataset \n",
        "    \n",
        "    Here are the links to download the data :\n",
        "    val and train  :  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "    test           :  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, subset, data_path):\n",
        "        \n",
        "        assert subset in ['train', 'val', 'trainval', 'test']\n",
        "        self.subset = subset\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.images_path = os.path.join(self.data_path, 'JPEGImages')\n",
        "        self.labels_path = os.path.join(self.data_path, 'ImageSets', 'Main')\n",
        "\n",
        "        # The id_to_label dict has the following structure\n",
        "        # key : image's id (e.g. 00084)\n",
        "        # value : image's label (e.g. [0, 0, 1, 0, ..., 1, 0])\n",
        "        self.id_to_label = {}\n",
        "\n",
        "        self.labels = LABELS\n",
        "        self.nb_classes = len(self.labels) # 20 classes for PascalVOC\n",
        "\n",
        "        # Get all the images' ids for the given subset\n",
        "        self.images_ids_in_subset = self._get_images_ids_from_subset(self.subset)\n",
        "        \n",
        "        # Create the id_to_label dict with all the images' ids \n",
        "        # but the values are arrays with nb_classes (20) zeros \n",
        "        self._initialize_id_to_label_dict()\n",
        "        \n",
        "        # Fill the values in the id_to_label dict by putting 1 when\n",
        "        # the label is in the image given by the key\n",
        "        self._fill_id_to_label_dict_with_classes()\n",
        "\n",
        "    def _initialize_id_to_label_dict(self):\n",
        "        for image_id in self.images_ids_in_subset:\n",
        "            self.id_to_label[image_id] = np.zeros(self.nb_classes)\n",
        "\n",
        "    def _fill_id_to_label_dict_with_classes(self):\n",
        "        \"\"\"_fill_id_to_label_dict_with_classes\n",
        "        For each class, the <class>_<subset>.txt file contain the presence information\n",
        "        of this class in the image\n",
        "        \"\"\"\n",
        "        for i in range(self.nb_classes):\n",
        "            label = self.labels[i]\n",
        "            # Open the <class>_<subset>.txt file\n",
        "            with open(os.path.join(self.labels_path, \"%s_%s.txt\" % (label, self.subset)), 'r') as f:\n",
        "                lines = f.read().splitlines()\n",
        "                for line in lines:\n",
        "                    splited_line = line.split()\n",
        "                    image_id = splited_line[0]\n",
        "                    is_present = int(splited_line[1])\n",
        "                    if is_present == 1:\n",
        "                        self.id_to_label[image_id][i] = 1\n",
        "\n",
        "    def _get_images_ids_from_subset(self, subset):\n",
        "        \"\"\"_get_images_ids_from_subset\n",
        "        The images' ids are found in the <subset>.txt file in ImageSets/Main\n",
        "        \"\"\"\n",
        "        with open(os.path.join(self.labels_path, subset + '.txt'), 'r') as f:\n",
        "            images_ids = f.read().splitlines()\n",
        "        return images_ids\n",
        "\n",
        "    def flow(self, batch_size=32):\n",
        "        \"\"\"flow\n",
        "        This is a generator which load the images and preprocess them on the fly\n",
        "        When calling next python build in function, it returns a batch with a given size\n",
        "        with a X_batch of size (None, IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "        and a Y_batch of size (None, nb_classes)\n",
        "        The first dimension is the batch_size if there is enough images left otherwise \n",
        "        it will be less\n",
        "\n",
        "        :param batch_size: the batch's size\n",
        "        \"\"\"\n",
        "        nb_batches = int(len(self.images_ids_in_subset) / batch_size) + 1\n",
        "        while True:\n",
        "            # Before each epoch we shuffle the images' ids\n",
        "            random.shuffle(self.images_ids_in_subset)\n",
        "            for i in range(nb_batches):\n",
        "                # We first get all the images' ids for the next batch\n",
        "                current_bach = self.images_ids_in_subset[i*batch_size:(i+1)*batch_size]\n",
        "                X_batch = []\n",
        "                Y_batch = []\n",
        "                for image_id in current_bach:\n",
        "                    # Load the image and resize it. We get a PIL Image object \n",
        "                    img = image.load_img(os.path.join(self.images_path, image_id + '.jpg'), grayscale=False, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "                    # Cast the Image object to a numpy array and put the channel has the last dimension\n",
        "                    img_arr = image.img_to_array(img, data_format='channels_last')\n",
        "                    X_batch.append(img_arr)\n",
        "                    Y_batch.append(self.id_to_label[image_id])\n",
        "                # resize X_batch in (batch_size, IMG_HEIGHT, IMG_WIDTH, 3) \n",
        "                X_batch = np.reshape(X_batch, (-1, IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "                # resize Y_batch in (None, nb_classes) \n",
        "                Y_batch = np.reshape(Y_batch, (-1, self.nb_classes))\n",
        "                # The preprocess consists of substracting the ImageNet RGB means values\n",
        "                # https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py#L72\n",
        "                X_batch = preprocess_input(X_batch, data_format='channels_last')\n",
        "                yield(X_batch, Y_batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wapQcwV-J-Uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n23psbOtHjZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import PascalVOCDataGenerator\n",
        "\n",
        "data_dir  = './content/data/VOCdevkit/VOC2007' # A changer avec votre chemin\n",
        "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)\n",
        "\n",
        "# trainset_dir = 'VOCdevkit/VOC2007' # A changer avec votre chemin\n",
        "# data_generator_train = PascalVOCDataGenerator('trainval', trainset_dir)\n",
        "\n",
        "# testset_dir = '/content/VOCdevkit/VOC2007' # A changer avec votre chemin\n",
        "# data_generator_test = PascalVOCDataGenerator('test', testset_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V68fHfuGHz_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator = data_generator_train.flow(batch_size=64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZsuSsMJOsH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "generator = data_generator_train.flow(batch_size=batch_size)\n",
        "# Initilisation des matrices contenant les Deep Features et les labels\n",
        "X_train = np.zeros((len(data_generator_train.images_ids_in_subset),2048))\n",
        "Y_train = np.zeros((len(data_generator_train.images_ids_in_subset),20))\n",
        "# Calcul du nombre e batchs\n",
        "nb_batches = int(len(data_generator_train.images_ids_in_subset) / batch_size) + 1\n",
        "\n",
        "for i in range(nb_batches):\n",
        "    # Pour chaque batch, on extrait les images d'entrée X et les labels y\n",
        "    X, y = next(generator)\n",
        "    # On récupère les Deep Feature par appel à predict\n",
        "    y_pred = model.predict(X)\n",
        "    print(\"y_pred shape: \",y_pred.shape)\n",
        "    print(\"X_train shape: \",X_train.shape)\n",
        "    # break\n",
        "    X_train[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
        "    Y_train[i*batch_size:(i+1)*batch_size,:] = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ZAQ092O-ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJw52st8wS6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir  = './content/data/VOCdevkit/VOC2007' # A changer avec votre chemin\n",
        "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "generator = data_generator_test.flow(batch_size=batch_size)\n",
        "# Initilisation des matrices contenant les Deep Features et les labels\n",
        "X_test = np.zeros((len(data_generator_test.images_ids_in_subset),2048))\n",
        "Y_test = np.zeros((len(data_generator_test.images_ids_in_subset),20))\n",
        "# Calcul du nombre e batchs\n",
        "nb_batches = int(len(data_generator_test.images_ids_in_subset) / batch_size) + 1\n",
        "\n",
        "for i in range(nb_batches):\n",
        "    # Pour chaque batch, on extrait les images d'entrée X et les labels y\n",
        "    X, y = next(generator)\n",
        "    # On récupère les Deep Feature par appel à predict\n",
        "    y_pred = model.predict(X)\n",
        "    print(\"y_pred shape: \",y_pred.shape)\n",
        "    print(\"X_test shape: \",X_test.shape)\n",
        "    # break\n",
        "    X_test[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
        "    Y_test[i*batch_size:(i+1)*batch_size,:] = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1geRAvpvwqkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outfile = 'DF_ResNet50_VOC2007'\n",
        "# Initilisation des matrices contenant les Deep Features et les labels\n",
        "# X_test = np.zeros((len(data_generator_test.images_ids_in_subset),2048))\n",
        "# Y_test = np.zeros((len(data_generator_test.images_ids_in_subset),20))\n",
        "np.savez(outfile, X_train=X_train, Y_train=Y_train,X_test=X_test, Y_test=Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcJzaYT9WfC_",
        "colab_type": "text"
      },
      "source": [
        "# **Exercice 3 : Transfert sur VOC 2007**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da2UBaX7PqwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "#from data_gen import PascalVOCDataGenerator\n",
        "###Transfer Learning\n",
        "outfile = '/content/DF_ResNet50_VOC2007.npz'\n",
        "npzfile = np.load(outfile)\n",
        "X_train = npzfile['X_train']\n",
        "Y_train = npzfile['Y_train']\n",
        "X_test = npzfile['X_test']\n",
        "Y_test = npzfile['Y_test']\n",
        "print (\"X_train=\",X_train.shape, \"Y_train=\",Y_train.shape, \" X_test=\",X_test.shape, \"Y_train=\",Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxcXPka5WLno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(20,  input_dim=2048, name='fc1', activation='sigmoid'))\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeyKH0CUWbFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "learning_rate = 0.1\n",
        "sgd = SGD(learning_rate)\n",
        "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['binary_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0PAAA6pWePu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "nb_epoch = 20\n",
        "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"%s TEST: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
        "print(\"%s TEST: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqWUEgKgWi8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "y_pred_test = model.predict(X_test)\n",
        "#y_pred_test = np.argmax(y_pred_test,axis=1)\n",
        "y_pred_train = model.predict(X_train)\n",
        "#y_pred_train = model.argmax(y_pred_train,axis=1)\n",
        "AP_train = np.zeros(20)\n",
        "AP_test = np.zeros(20)\n",
        "for c in range(20):\n",
        "    AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
        "    AP_test[c] = average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
        "\n",
        "print (\"MAP TRAIN =\", AP_train.mean()*100)\n",
        "print (\"MAP TEST =\", AP_test.mean()*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouGzHiXTyHHj",
        "colab_type": "text"
      },
      "source": [
        "# **Exercice 4 : Fine-tuning sur VOC 2007**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxXx_c1uWsIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nAx1BCYyUYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load ResNet50 architecture & its weights\n",
        "# model = Model(inputs=model.inputs , outputs=model.layers[-2].output)\n",
        "\n",
        "model = ResNet50(include_top=True, weights='imagenet')\n",
        "model.layers.pop()\n",
        "# Modify top layers\n",
        "x = model.layers[-1].output\n",
        "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
        "model = Model(inputs=model.inputs,outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAByE21P0X-F",
        "colab_type": "text"
      },
      "source": [
        "Freezing the layers except the last 4 layers\n",
        "\n",
        "for layer in conv_base.layers[:-4]:\n",
        "\n",
        "layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCRKEIbjyj2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()\n",
        "for i in range(len(model.layers)):\n",
        "  model.layers[i].trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx54xKnXy9GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.1\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr), metrics=['binary_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEuX-HFSzvbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=32\n",
        "nb_epochs=10\n",
        "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)\n",
        "steps_per_epoch_train = int(len(data_generator_train.id_to_label) / batch_size) + 1\n",
        "model.fit_generator(data_generator_train.flow(batch_size=batch_size),\n",
        "                    steps_per_epoch=steps_per_epoch_train,\n",
        "                    epochs=nb_epochs,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uidSYM46pD3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKUh5cIr0kCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "# import PascalVOCDataGenerator\n",
        "\n",
        "default_batch_size = 200\n",
        "default_data_dir = './content/data/VOCdevkit/VOC2007'\n",
        "\n",
        "def evaluate(model, subset, batch_size=default_batch_size, data_dir=default_data_dir, verbose=1):\n",
        "    \"\"\"evaluate\n",
        "    Compute the mean Average Precision metrics on a subset with a given model\n",
        "\n",
        "    :param model: the model to evaluate\n",
        "    :param subset: the data subset\n",
        "    :param batch_size: the batch which will be use in the data generator\n",
        "    :param data_dir: the directory where the data is stored\n",
        "    :param verbose: display a progress bar or not, default is no (0)\n",
        "    \"\"\"\n",
        "    #disable_tqdm = (verbose == 0)\n",
        "\n",
        "    # Create the generator on the given subset\n",
        "    data_generator = PascalVOCDataGenerator(subset, data_dir)\n",
        "    steps_per_epoch = int(len(data_generator.id_to_label) / batch_size) + 1\n",
        "\n",
        "    # Get the generator\n",
        "    generator = data_generator.flow(batch_size=batch_size)\n",
        "\n",
        "    y_all = []\n",
        "    y_pred_all = []\n",
        "    for i in range(steps_per_epoch):\n",
        "        # Get the next batch\n",
        "        X, y = next(generator)\n",
        "        y_pred = model.predict(X)\n",
        "        # We concatenate all the y and the prediction\n",
        "        for y_sample, y_pred_sample in zip(y, y_pred):\n",
        "            y_all.append(y_sample)\n",
        "            y_pred_all.append(y_pred_sample)\n",
        "    y_all = np.array(y_all)\n",
        "    y_pred_all = np.array(y_pred_all)\n",
        "\n",
        "    # Now we can compute the AP for each class\n",
        "    AP = np.zeros(data_generator.nb_classes)\n",
        "    for cl in range(data_generator.nb_classes):\n",
        "        AP[cl] = average_precision_score(y_all[:, cl], y_pred_all[:, cl])\n",
        "    MAP = AP.mean()*100\n",
        "    \n",
        "    return AP, MAP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJqYArD61uqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset = 'train'\n",
        "AP, MAP = evaluate(model, subset)\n",
        "print (\"MAP  =\", MAP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6et3ADO3HJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset = 'test'\n",
        "AP, MAP = evaluate(model, subset)\n",
        "print (\"MAP  =\", MAP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3P6D8xE6vcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}